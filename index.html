<!doctype html>
<html lang="de">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="./favicon.png" />
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link href="https://fonts.googleapis.com/css2?family=Jersey+10&display=swap" rel="stylesheet" />
		

		<meta name="viewport" content="width=device-width, initial-scale=1" />

		<!-- Haupt-Meta-Tags -->
		<meta name="title" content="Transformer Erklärer: LLM Transformer-Modell visuell erklärt" />
		<meta
			name="description"
			content="Ein interaktives Visualisierungswerkzeug, das zeigt, wie Transformermodelle in großen Sprachmodellen (LLM) wie GPT funktionieren."
		/>

		<!-- Open Graph / Facebook -->
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://poloclub.github.io/transformer-explainer/" />
		<meta
			property="og:title"
			content="Transformer Erklärer: LLM Transformer-Modell visuell erklärt"
		/>
		<meta
			property="og:description"
			content="Ein interaktives Visualisierungswerkzeug, das zeigt, wie Transformermodelle in großen Sprachmodellen (LLM) wie GPT funktionieren."
		/>
		<meta
			property="og:image"
			content="https://poloclub.github.io/transformer-explainer/preview/summary.png"
		/>

		<!-- Twitter -->
		<meta property="twitter:card" content="summary_large_image" />
		<meta property="twitter:url" content="https://poloclub.github.io/transformer-explainer/" />
		<meta
			property="twitter:title"
			content="Transformer Erklärer: LLM Transformer-Modell visuell erklärt"
		/>
		<meta
			property="twitter:description"
			content="Ein interaktives Visualisierungswerkzeug, das zeigt, wie Transformermodelle in großen Sprachmodellen (LLM) wie GPT funktionieren."
		/>
		<meta
			property="twitter:image"
			content="https://poloclub.github.io/transformer-explainer/preview/summary.png"
		/>

		<link href="./_app/immutable/assets/0.ZHkuq1AD.css" rel="stylesheet">
		<link href="./_app/immutable/assets/HelpPopover.C2kW60Kz.css" rel="stylesheet">
		<link href="./_app/immutable/assets/2.BB2dfHRT.css" rel="stylesheet">
		<link href="./_app/immutable/assets/QKVWeightPopover.BAjhBQfT.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.DbKADbpB.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/entry.DA2jIMt1.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.if_DmnYd.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.D9ecZZ3B.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/paths.XGB25dDP.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.DPlfBxt2.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.J3wHlIuA.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.J4Kxt1gr.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.CLdE35_6.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/HelpPopover.BWfg9bBo.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.CLHtpUPn.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/QKVWeightPopover.CTvhStdE.js">
		<!-- Google Tag (gtag.js) -->
		<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.css" />
		<script src="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.js"></script>
		<script>
			window.addEventListener("load", function() {
				window.cookieconsent.initialise({
					palette: {
						popup: {
							background: "#000"
						},
						button: {
							background: "#f1d600"
						}
					},
					theme: "classic",
					type: "opt-in", // Ensure tracking only happens after user consent
					content: {
						message: "Diese Website verwendet Cookies, um sicherzustellen, dass Sie die beste Erfahrung auf unserer Website machen.",
						dismiss: "Akzeptieren",
						deny: "Ablehnen",
						link: "Mehr erfahren",
						href: "/datenschutz" // Link to your privacy policy
					},
					elements: {
						messagelink: '<span id="cookieconsent:desc" class="cc-message">{{message}} <a aria-label="learn more about cookies" tabindex="0" class="cc-link" href="{{href}}" target="_blank">{{link}}</a></span>',
						allow: '<button aria-label="allow cookies" tabindex="0" class="cc-btn cc-allow">{{dismiss}}</button>',
						deny: '<button aria-label="deny cookies" tabindex="0" class="cc-btn cc-deny">{{deny}}</button>'
					},
					onInitialise: function (status) {
						if (this.hasConsented()) {
							loadGoogleAnalytics();
						}
					},
					onStatusChange: function(status, chosenBefore) {
						if (this.hasConsented()) {
							loadGoogleAnalytics();
						} else {
							disableGoogleAnalytics();
						}
					}
				});
		
				function loadGoogleAnalytics() {
					(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
					(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
					m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
					})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
		
					ga('create', 'GTM-5PXWCT22', 'auto'); // Replace with your Google Analytics ID
					ga('send', 'pageview');
				}
		
				function disableGoogleAnalytics() {
					window['ga-disable-GTM-5PXWCT22'] = true; // Replace with your Google Analytics ID
				}
			});
		</script> -->
		
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">  <div id="app" style="--min-screen-width:1300px;--min-column-width:22px;--predicted-color:#7E3AF2;" class="svelte-1efe9k3"><div id="landing" class="svelte-1efe9k3"><header class="svelte-1efe9k3"><div class="top-bar flex w-full items-center gap-4 px-10 py-2 pb-3 svelte-1i2onu1"><div class="logo text-bold text-gray-700 svelte-1i2onu1" data-svelte-h="svelte-793i68">T<span class="small svelte-1i2onu1">RANSFORMER</span> E<span class="small svelte-1i2onu1">XPLAINER</span></div> <div class="inputs flex grow items-center"><div class="input-wrapper w-full svelte-1i2onu1"><div class="input-area svelte-1v1a3hy">    <form class="input-form svelte-1v1a3hy"><div class="inline-flex rounded-lg shadow-sm input-btn-group" role="group"><button type="button"  class="select-button inline-flex shrink-0 items-center justify-center border border-s-0 border-gray-200 bg-white px-3 py-2 text-center text-xs font-medium text-gray-900 first:rounded-s-lg first:border-s last:rounded-e-lg svelte-1v1a3hy">Beispiele<svg xmlns="http://www.w3.org/2000/svg" fill="none" color="currentColor" class="shrink-0 pointer-events-none h-4 w-4 text-gray-500" role="img" aria-label="chevron down outline" viewBox="0 0 24 24"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m8 10 4 4 4-4"></path></svg> </button> <div></div>    <div class="input-container svelte-1v1a3hy disabled"><div class="editable w-full svelte-1v1a3hy"><div contenteditable="false" class="text-box svelte-1v1a3hy" placeholder="Testen Sie Ihren eigenen Text" role="input">Datenvisualisierung ermöglicht es Benutzern</div> <div class="predicted svelte-1v1a3hy" role="none"><span class="svelte-1v1a3hy"> zu erstellen</span></div></div>  </div></div>  <button disabled class="generate-button rounded-lg text-center text-sm shadow-sm disabled svelte-1v1a3hy" type="submit">Generieren</button></form> <div class="temperature-slider shrink-0 text-gray-900 svelte-snflhu"><div class="slider-container flex w-full flex-col items-end svelte-snflhu"><div class="flex w-full shrink-0 items-center justify-between"><div class="temperature-text flex items-center gap-[2px] svelte-snflhu"><div data-svelte-h="svelte-knfc80">Temperatur</div> <div id="temperature-help" class="help"><svg class="h-4 w-4 text-gray-300" xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960" fill="currentColor"><path d="M478-240q21 0 35.5-14.5T528-290q0-21-14.5-35.5T478-340q-21 0-35.5 14.5T428-290q0 21 14.5 35.5T478-240Zm-36-154h74q0-33 7.5-52t42.5-52q26-26 41-49.5t15-56.5q0-56-41-86t-97-30q-57 0-92.5 30T342-618l66 26q5-18 22.5-39t53.5-21q32 0 48 17.5t16 38.5q0 20-12 37.5T506-526q-44 39-54 59t-10 73Zm38 314q-83 0-156-31.5T197-197q-54-54-85.5-127T80-480q0-83 31.5-156T197-763q54-54 127-85.5T480-880q83 0 156 31.5T763-763q54 54 85.5 127T880-480q0 83-31.5 156T763-197q-54 54-127 85.5T480-80Z"></path></svg></div> <div></div>   </div> <div class="temperature-value svelte-snflhu"><p>1</p></div></div> <input disabled class="slider svelte-snflhu" type="range" min="0" max="17" step="1" value="8"></div> </div> </div></div></div> <div class="icons flex items-center gap-3 svelte-1i2onu1" data-svelte-h="svelte-xbnsiy"> <a href="https://arxiv.org/abs/2408.04619" target="_blank"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1i2onu1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M9 2.221V7H4.221a2 2 0 0 1 .365-.5L8.5 2.586A2 2 0 0 1 9 2.22ZM11 2v5a2 2 0 0 1-2 2H4a2 2 0 0 0-2 2v7a2 2 0 0 0 2 2 2 2 0 0 0 2 2h12a2 2 0 0 0 2-2 2 2 0 0 0 2-2v-7a2 2 0 0 0-2-2V4a2 2 0 0 0-2-2h-7Zm-6 9a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h.5a2.5 2.5 0 0 0 0-5H5Zm1.5 3H6v-1h.5a.5.5 0 0 1 0 1Zm4.5-3a1 1 0 0 0-1 1v5a1 1 0 0 0 1 1h1.376A2.626 2.626 0 0 0 15 15.375v-1.75A2.626 2.626 0 0 0 12.375 11H11Zm1 5v-3h.375a.626.626 0 0 1 .625.626v1.748a.625.625 0 0 1-.626.626H12Zm5-5a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h1a1 1 0 1 0 0-2h-1v-1h1a1 1 0 1 0 0-2h-2Z" clip-rule="evenodd"></path></svg></a>  <a href="https://www.youtube.com/watch?v=ECR4oAwocjs" target="_blank"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1i2onu1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M21.7 8.037a4.26 4.26 0 0 0-.789-1.964 2.84 2.84 0 0 0-1.984-.839c-2.767-.2-6.926-.2-6.926-.2s-4.157 0-6.928.2a2.836 2.836 0 0 0-1.983.839 4.225 4.225 0 0 0-.79 1.965 30.146 30.146 0 0 0-.2 3.206v1.5a30.12 30.12 0 0 0 .2 3.206c.094.712.364 1.39.784 1.972.604.536 1.38.837 2.187.848 1.583.151 6.731.2 6.731.2s4.161 0 6.928-.2a2.844 2.844 0 0 0 1.985-.84 4.27 4.27 0 0 0 .787-1.965 30.12 30.12 0 0 0 .2-3.206v-1.516a30.672 30.672 0 0 0-.202-3.206Zm-11.692 6.554v-5.62l5.4 2.819-5.4 2.801Z" clip-rule="evenodd"></path></svg></a>  <a href="https://github.com/poloclub/transformer-explainer" target="_blank"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1i2onu1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M12.006 2a9.847 9.847 0 0 0-6.484 2.44 10.32 10.32 0 0 0-3.393 6.17 10.48 10.48 0 0 0 1.317 6.955 10.045 10.045 0 0 0 5.4 4.418c.504.095.683-.223.683-.494 0-.245-.01-1.052-.014-1.908-2.78.62-3.366-1.21-3.366-1.21a2.711 2.711 0 0 0-1.11-1.5c-.907-.637.07-.621.07-.621.317.044.62.163.885.346.266.183.487.426.647.71.135.253.318.476.538.655a2.079 2.079 0 0 0 2.37.196c.045-.52.27-1.006.635-1.37-2.219-.259-4.554-1.138-4.554-5.07a4.022 4.022 0 0 1 1.031-2.75 3.77 3.77 0 0 1 .096-2.713s.839-.275 2.749 1.05a9.26 9.26 0 0 1 5.004 0c1.906-1.325 2.74-1.05 2.74-1.05.37.858.406 1.828.101 2.713a4.017 4.017 0 0 1 1.029 2.75c0 3.939-2.339 4.805-4.564 5.058a2.471 2.471 0 0 1 .679 1.897c0 1.372-.012 2.477-.012 2.814 0 .272.18.592.687.492a10.05 10.05 0 0 0 5.388-4.421 10.473 10.473 0 0 0 1.313-6.948 10.32 10.32 0 0 0-3.39-6.165A9.847 9.847 0 0 0 12.007 2Z" clip-rule="evenodd"></path></svg></a></div> </div></header> <main id="main" style="padding-top:0px" class="svelte-1efe9k3"><div class="flex h-full w-full items-center justify-center"><svg role="status" class="inline -mt-px animate-spin dark:text-gray-600 w-8 h-8 text-gray-300 fill-purple-600" viewBox="0 0 100 101" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M100 50.5908C100 78.2051 77.6142 100.591 50 100.591C22.3858 100.591 0 78.2051 0 50.5908C0 22.9766 22.3858 0.59082 50 0.59082C77.6142 0.59082 100 22.9766 100 50.5908ZM9.08144 50.5908C9.08144 73.1895 27.4013 91.5094 50 91.5094C72.5987 91.5094 90.9186 73.1895 90.9186 50.5908C90.9186 27.9921 72.5987 9.67226 50 9.67226C27.4013 9.67226 9.08144 27.9921 9.08144 50.5908Z" fill="currentColor"></path><path d="M93.9676 39.0409C96.393 38.4038 97.8624 35.9116 97.0079 33.5539C95.2932 28.8227 92.871 24.3692 89.8167 20.348C85.8452 15.1192 80.8826 10.7238 75.2124 7.41289C69.5422 4.10194 63.2754 1.94025 56.7698 1.05124C51.7666 0.367541 46.6976 0.446843 41.7345 1.27873C39.2613 1.69328 37.813 4.19778 38.4501 6.62326C39.0873 9.04874 41.5694 10.4717 44.0505 10.1071C47.8511 9.54855 51.7191 9.52689 55.5402 10.0491C60.8642 10.7766 65.9928 12.5457 70.6331 15.2552C75.2735 17.9648 79.3347 21.5619 82.5849 25.841C84.9175 28.9121 86.7997 32.2913 88.1811 35.8758C89.083 38.2158 91.5421 39.6781 93.9676 39.0409Z" fill="currentFill"></path></svg> </div></main></div> <div class="article h-auto w-full"><div id="description" class="svelte-s9hg3b" data-svelte-h="svelte-1ddksfh"><div class="article-section svelte-s9hg3b"><h1 class="svelte-s9hg3b">Was ist ein Transformer?</h1> <p class="svelte-s9hg3b">Ein Transformer ist eine neuronale Netzwerkarchitektur, die die Herangehensweise an künstliche Intelligenz grundlegend verändert hat. Der Transformer wurde erstmals in dem bahnbrechenden Artikel <a href="https://dl.acm.org/doi/10.5555/3295222.3295349" title="ACM Digital Library" target="_blank" class="svelte-s9hg3b">„Attention is All You Need“</a> im Jahr 2017 vorgestellt und hat sich seitdem zur bevorzugten Architektur für Deep-Learning-Modelle entwickelt. Diese Modelle betreiben unter anderem textgenerative Modelle wie OpenAI's <strong>GPT</strong>, Meta's <strong>Llama</strong> und Google's <strong>Gemini</strong>. Über den Text hinaus wird der Transformer auch in <a href="https://huggingface.co/learn/audio-course/en/chapter3/introduction" title="Hugging Face" target="_blank" class="svelte-s9hg3b">Audio-Generierung</a>, <a href="https://huggingface.co/learn/computer-vision-course/unit3/vision-transformers/vision-transformers-for-image-classification" title="Hugging Face" target="_blank" class="svelte-s9hg3b">Bilderkennung</a>, <a href="https://elifesciences.org/articles/82819" title="eLife" class="svelte-s9hg3b">Proteinstruktur-Vorhersage</a> und sogar <a href="https://www.deeplearning.ai/the-batch/reinforcement-learning-plus-transformers-equals-efficiency/" title="Deep Learning AI" target="_blank" class="svelte-s9hg3b">Spiele</a> angewendet, was seine Vielseitigkeit in verschiedenen Bereichen zeigt.</p> <p class="svelte-s9hg3b">Im Wesentlichen arbeiten textgenerative Transformermodelle nach dem Prinzip der <strong>Vorhersage des nächsten Wortes</strong>: Angenommen, es gibt einen Textvorschlag des Benutzers, dann wird das <em>wahrscheinlichste nächste Wort</em> ermittelt, das diesem Eingabetext folgen würde. Die Kerninnovation und Stärke des Transformers liegt in der Verwendung des Self-Attention-Mechanismus, der es ermöglicht, ganze Sequenzen zu verarbeiten und langfristige Abhängigkeiten effektiver zu erfassen als frühere Architekturen.</p> <p class="svelte-s9hg3b">Die GPT-2-Familie von Modellen ist ein herausragendes Beispiel für textgenerative Transformer. Der Transformer Erklärer wird vom <a href="https://huggingface.co/openai-community/gpt2" title="Hugging Face" target="_blank" class="svelte-s9hg3b">GPT-2</a> (klein) Modell angetrieben, das über 124 Millionen Parameter verfügt. Während es nicht das neueste oder leistungsstärkste Transformermodell ist, teilt es viele der gleichen architektonischen Komponenten und Prinzipien mit den aktuellen Spitzenmodellen, was es zu einem idealen Ausgangspunkt macht, um die Grundlagen zu verstehen.</p></div> <div class="article-section svelte-s9hg3b"><h1 class="svelte-s9hg3b">Transformer-Architektur</h1> <p class="svelte-s9hg3b">Jeder textgenerative Transformer besteht aus diesen <strong>drei Schlüsselelementen</strong>:</p> <ol class="svelte-s9hg3b"><li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Embedding</strong>: Der Texteingang wird in kleinere Einheiten unterteilt, sogenannte Tokens, die Wörter oder Wortteile sein können. Diese Tokens werden in numerische Vektoren, sogenannte Embeddings, umgewandelt, die die semantische Bedeutung der Wörter erfassen.</li> <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Transformer Block</strong>: Dies ist das grundlegende Bauelement des Modells, das die Eingabedaten verarbeitet und transformiert. Jeder Block umfasst:
				<ul class=" svelte-s9hg3b"><li class="svelte-s9hg3b"><strong>Attention Mechanism</strong>, das zentrale Element des Transformer Blocks. Er ermöglicht es Tokens, miteinander zu kommunizieren und kontextuelle Informationen sowie Beziehungen zwischen Wörtern zu erfassen.</li> <li class="svelte-s9hg3b"><strong>MLP (Multilayer Perceptron) Layer</strong>, ein Feedforward-Netzwerk, das auf jedes Token unabhängig wirkt. Während der Zweck der Attention-Schicht darin besteht, Informationen zwischen Tokens zu leiten, besteht das Ziel des MLP darin, die Darstellung jedes Tokens zu verfeinern.</li></ul></li> <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Ausgabe-Wahrscheinlichkeiten</strong>: Die abschließenden linearen und Softmax-Schichten wandeln die verarbeiteten Embeddings in Wahrscheinlichkeiten um, wodurch das Modell Vorhersagen über das nächste Token in einer Sequenz treffen kann.</li></ol> <div class="architecture-section svelte-s9hg3b" id="embedding"><h2 class="svelte-s9hg3b">Embedding</h2> <p class="svelte-s9hg3b">Angenommen, Sie möchten mit einem Transformer-Modell Text generieren. Sie geben den Textvorschlag ein, zum Beispiel: <code class="svelte-s9hg3b">„Datenvisualisierung ermöglicht es Benutzern“</code>. Diese Eingabe muss in ein Format umgewandelt werden, das das Modell verstehen und verarbeiten kann. Hier kommt das Embedding ins Spiel: Es wandelt den Text in eine numerische Darstellung um, mit der das Modell arbeiten kann. Um einen Textvorschlag in ein Embedding zu verwandeln, müssen wir 1) die Eingabe tokenisieren, 2) Token-Embeddings erhalten, 3) Positionsinformationen hinzufügen und schließlich 4) Token- und Positionscodierungen addieren, um das endgültige Embedding zu erhalten. Schauen wir uns an, wie jeder dieser Schritte durchgeführt wird.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/embedding.png" width="60%" height="60%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">1</span>. Erweiterung der Ansicht der Embedding-Schicht, die zeigt, wie der Eingabetext in eine Vektor-Darstellung umgewandelt wird. Der Prozess umfasst <span class="fig-numbering">(1)</span> Tokenisierung, (2) Token-Embedding, (3) Positionscodierung und (4) finales Embedding.</div> <div class="article-subsection svelte-s9hg3b"><h3 class="svelte-s9hg3b">Schritt 1: Tokenisierung</h3> <p class="svelte-s9hg3b">Die Tokenisierung ist der Prozess, bei dem der Eingabetext in kleinere, leichter handhabbare Teile, sogenannte Tokens, zerlegt wird. Diese Tokens können ein Wort oder ein Wortteil sein. Die Wörter <code class="svelte-s9hg3b">„Daten“</code> und <code class="svelte-s9hg3b">„Visualisierung“</code> entsprechen einzigartigen Tokens, während das Wort <code class="svelte-s9hg3b">„ermöglicht“</code> in zwei Tokens aufgeteilt wird. Der vollständige Token-Wortschatz wird vor dem Training des Modells festgelegt: Das GPT-2-Wortschatz umfasst <code class="svelte-s9hg3b">50.257</code> einzigartige Tokens. Nun, da wir unseren Eingabetext in Tokens mit eindeutigen IDs aufgeteilt haben, können wir deren Vektor-Darstellung aus Embeddings erhalten.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-token-embedding"><h3 class="svelte-s9hg3b">Schritt 2: Token-Embedding</h3> <p class="svelte-s9hg3b">Das GPT-2 Small-Modell stellt jedes Token im Wortschatz als 768-dimensionalen Vektor dar; die Dimension des Vektors hängt vom Modell ab. Diese Embedding-Vektoren sind in einer Matrix mit der Form <code class="svelte-s9hg3b">(50.257, 768)</code> gespeichert, die ungefähr 39 Millionen Parameter enthält! Diese umfangreiche Matrix ermöglicht es dem Modell, jedem Token eine semantische Bedeutung zuzuweisen.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-positional-embedding"><h3 class="svelte-s9hg3b">Schritt 3: Positionscodierung</h3> <p class="svelte-s9hg3b">Die Embedding-Schicht codiert auch Informationen über die Position jedes Tokens im Eingabetext. Verschiedene Modelle verwenden unterschiedliche Methoden für die Positionscodierung. GPT-2 trainiert seine eigene Positionscodierungs-Matrix von Grund auf neu und integriert sie direkt in den Trainingsprozess.</p> </div> <div class="article-subsection svelte-s9hg3b"><h3 class="svelte-s9hg3b">Schritt 4: Finale Embedding</h3> <p class="svelte-s9hg3b">Schließlich summieren wir die Token- und Positionscodierungen, um die endgültige Embedding-Darstellung zu erhalten. Diese kombinierte Darstellung erfasst sowohl die semantische Bedeutung der Tokens als auch ihre Position in der Eingabesequenz.</p></div></div> <div class="architecture-section svelte-s9hg3b"><h2 class="svelte-s9hg3b">Transformer Block</h2> <p class="svelte-s9hg3b">Der Kern der Verarbeitung eines Transformers liegt im Transformer Block, der aus Multi-Head-Self-Attention und einer Multi-Layer-Perceptron-Schicht besteht. Die meisten Modelle bestehen aus mehreren solcher Blöcke, die nacheinander gestapelt sind. Die Token-Darstellungen entwickeln sich durch die Schichten, vom ersten Block bis zum zwölften, was es dem Modell ermöglicht, ein detailliertes Verständnis jedes Tokens aufzubauen. Dieser schichtweise Ansatz führt zu höheren Repräsentationen der Eingabe.</p> <div class="article-subsection svelte-s9hg3b" id="self-attention"><h3 class="svelte-s9hg3b">Multi-Head-Self-Attention</h3> <p class="svelte-s9hg3b">Der Self-Attention-Mechanismus ermöglicht es dem Modell, sich auf relevante Teile der Eingabesequenz zu konzentrieren, wodurch es komplexe Beziehungen und Abhängigkeiten innerhalb der Daten erfassen kann. Schauen wir uns an, wie diese Self-Attention Schritt für Schritt berechnet wird.</p> <div class="article-subsection-l2 svelte-s9hg3b"><h4 class="svelte-s9hg3b">Schritt 1: Query, Key und Value-Matrizen</h4> <div class="figure svelte-s9hg3b"><img src="./article_assets/QKV.png" width="80%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">2</span>. Berechnung der Query-, Key- und Value-Matrizen aus dem ursprünglichen Embedding.</div> <p class="svelte-s9hg3b">Jedes Token's Embedding-Vektor wird in drei Vektoren umgewandelt: <span class="q-color svelte-s9hg3b">Query (Q)</span>, <span class="k-color svelte-s9hg3b">Key (K)</span> und <span class="v-color svelte-s9hg3b">Value (V)</span>. Diese Vektoren werden durch Multiplikation der Eingabe-Embedding-Matrix mit erlernten Gewichtsmatrizen für <span class="q-color svelte-s9hg3b">Q</span>, <span class="k-color svelte-s9hg3b">K</span> und <span class="v-color svelte-s9hg3b">V</span> abgeleitet. Hier ist eine Websuche-Analogie, um uns ein Verständnis für diese Matrizen zu vermitteln:</p> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><strong class="q-color font-medium svelte-s9hg3b">Query (Q)</strong> ist der Suchtext, den Sie in die Suchleiste eingeben. Dies ist das Token, zu dem Sie <em>„mehr Informationen finden“</em> möchten.</li> <li class="svelte-s9hg3b"><strong class="k-color font-medium svelte-s9hg3b">Key (K)</strong> ist der Titel jeder Webseite im Suchergebnisfenster. Es stellt die möglichen Tokens dar, auf die sich die Query beziehen kann.</li> <li class="svelte-s9hg3b"><strong class="v-color font-medium svelte-s9hg3b">Value (V)</strong> ist der eigentliche Inhalt der angezeigten Webseiten. Sobald wir den entsprechenden Suchbegriff (Query) mit den relevanten Ergebnissen (Key) abgeglichen haben, möchten wir den Inhalt (Value) der relevantesten Seiten erhalten.</li></ul> <p class="svelte-s9hg3b">Mit Hilfe dieser QKV-Werte kann das Modell Aufmerksamkeitspunkte berechnen, die bestimmen, wie viel Aufmerksamkeit jedes Token erhalten sollte, wenn es Vorhersagen trifft.</p></div> <div class="article-subsection-l2 svelte-s9hg3b"><h4 class="svelte-s9hg3b">Schritt 2: Maskierte Self-Attention</h4> <p class="svelte-s9hg3b">Die maskierte Self-Attention ermöglicht es dem Modell, Sequenzen zu generieren, indem es sich auf relevante Teile der Eingabe konzentriert, während der Zugriff auf zukünftige Tokens verhindert wird.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/attention.png" width="80%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">3</span>. Verwendung von Query-, Key- und Value-Matrizen zur Berechnung der maskierten Self-Attention.</div> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><strong>Attention-Score</strong>: Das Skalarprodukt der <span class="q-color svelte-s9hg3b">Query</span> und <span class="k-color svelte-s9hg3b">Key</span> Matrizen bestimmt die Übereinstimmung jeder Query mit jedem Key und erzeugt eine quadratische Matrix, die die Beziehung zwischen allen Eingabe-Tokens widerspiegelt.</li> <li class="svelte-s9hg3b"><strong>Maskierung</strong>: Eine Maske wird auf das obere Dreieck der Attention-Matrix angewendet, um zu verhindern, dass das Modell auf zukünftige Tokens zugreift, indem diese Werte auf negative Unendlichkeit gesetzt werden. Das Modell muss lernen, das nächste Token vorherzusagen, ohne in die Zukunft zu „blicken“.</li> <li class="svelte-s9hg3b"><strong>Softmax</strong>: Nach der Maskierung wird der Attention-Score durch die Softmax-Operation in eine Wahrscheinlichkeit umgewandelt, bei der das Exponential jedes Attention-Scores genommen wird. Jede Zeile der Matrix summiert sich auf eins und zeigt die Relevanz jedes anderen Tokens links davon an.</li></ul></div> <div class="article-subsection-l2 svelte-s9hg3b"><h4 class="svelte-s9hg3b">Schritt 3: Ausgabe</h4> <p class="svelte-s9hg3b">Das Modell verwendet die maskierten Self-Attention-Scores und multipliziert sie mit der <span class="v-color svelte-s9hg3b">Value</span> Matrix, um die <span class="purple-color svelte-s9hg3b">endgültige Ausgabe</span> des Self-Attention-Mechanismus zu erhalten. GPT-2 verfügt über <code class="svelte-s9hg3b">12</code> Self-Attention-Köpfe, von denen jeder verschiedene Beziehungen zwischen Tokens erfasst. Die Ausgaben dieser Köpfe werden zusammengeführt und durch eine lineare Projektion weitergeleitet.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-activation"><h3 class="svelte-s9hg3b">MLP: Multi-Layer Perceptron</h3> <div class="figure svelte-s9hg3b"><img src="./article_assets/mlp.png" width="70%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">4</span>. Verwendung der MLP-Schicht zur Projektion der Self-Attention-Darstellungen in höhere Dimensionen, um die Repräsentationskapazität des Modells zu verbessern.</div> <p class="svelte-s9hg3b">Nachdem die verschiedenen Self-Attention-Köpfe die vielfältigen Beziehungen zwischen den Eingabe-Tokens erfasst haben, werden die zusammengeführten Ausgaben durch die Multilayer-Perceptron-Schicht (MLP) weitergeleitet, um die Repräsentationskapazität des Modells zu verbessern. Der MLP-Block besteht aus zwei linearen Transformationen mit einer GELU-Aktivierungsfunktion dazwischen. Die erste lineare Transformation erhöht die Dimension der Eingabe um das Vierfache, von <code class="svelte-s9hg3b">768</code> auf <code class="svelte-s9hg3b">3072</code>. Die zweite lineare Transformation reduziert die Dimension wieder auf die ursprüngliche Größe von <code class="svelte-s9hg3b">768</code>, um sicherzustellen, dass die nachfolgenden Schichten Eingaben mit konsistenten Dimensionen erhalten. Im Gegensatz zum Self-Attention-Mechanismus verarbeitet die MLP Tokens unabhängig voneinander und ordnet sie einfach von einer Darstellung in eine andere um.</p></div> <div class="architecture-section svelte-s9hg3b" id="article-prob"><h2 class="svelte-s9hg3b">Ausgabe-Wahrscheinlichkeiten</h2> <p class="svelte-s9hg3b">Nachdem die Eingabe durch alle Transformer-Blöcke verarbeitet wurde, wird die Ausgabe durch die abschließende lineare Schicht geleitet, um sie auf die Token-Vorhersage vorzubereiten. Diese Schicht projiziert die endgültigen Darstellungen in einen <code class="svelte-s9hg3b">50.257</code> dimensionalen Raum, in dem jedes Token im Wortschatz einen entsprechenden Wert, genannt <code class="svelte-s9hg3b">Logit</code>, hat. Jedes Token kann das nächste Wort sein, daher ermöglicht uns dieser Prozess, diese Tokens einfach nach ihrer Wahrscheinlichkeit zu ordnen, das nächste Wort zu sein. Anschließend wird die Softmax-Funktion angewendet, um die Logits in eine Wahrscheinlichkeitsverteilung umzuwandeln, die sich auf eins summiert. Dies ermöglicht es uns, das nächste Token basierend auf seiner Wahrscheinlichkeit auszuwählen.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/softmax.png" width="60%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">5</span>. Jedem Token im Wortschatz wird basierend auf den Logits des Modells eine Wahrscheinlichkeit zugewiesen. Diese Wahrscheinlichkeiten bestimmen, wie wahrscheinlich es ist, dass jedes Token das nächste Wort in der Sequenz ist.</div> <p id="article-temperature" class="svelte-s9hg3b">Der letzte Schritt besteht darin, das nächste Token zu generieren, indem aus dieser Verteilung ausgewählt wird. Der <code class="svelte-s9hg3b">Temperatur</code>-Hyperparameter spielt in diesem Prozess eine entscheidende Rolle. Mathematisch gesehen ist es ein sehr einfacher Vorgang: Die Logits der Modellausgabe werden einfach durch die <code class="svelte-s9hg3b">Temperatur</code> geteilt:</p> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><code class="svelte-s9hg3b">Temperatur = 1</code>: Die Division der Logits durch eins hat keine Auswirkungen auf die Softmax-Ausgaben.</li> <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">Temperatur < 1</code>: Eine niedrigere Temperatur macht das Modell selbstsicherer und deterministischer, indem es die Wahrscheinlichkeitsverteilung schärft, was zu vorhersehbareren Ausgaben führt.</li> <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">Temperatur > 1</code>: Eine höhere Temperatur führt zu einer weicheren Wahrscheinlichkeitsverteilung, was zu mehr Zufälligkeit im generierten Text führt – was manche als „Kreativität“ des Modells bezeichnen.</li></ul> <p class="svelte-s9hg3b">Passen Sie die Temperatur an und sehen Sie, wie Sie die Balance zwischen deterministischen und vielfältigen Ausgaben finden können!</p></div> <div class="architecture-section svelte-s9hg3b"><h2 class="svelte-s9hg3b">Erweiterte Architektonische Funktionen</h2> <p class="svelte-s9hg3b">Es gibt mehrere erweiterte architektonische Funktionen, die die Leistung von Transformer-Modellen verbessern. Während sie für die Gesamtleistung des Modells wichtig sind, sind sie nicht so entscheidend, um die Grundkonzepte der Architektur zu verstehen. Layer Normalization, Dropout und Residual Connections sind entscheidende Komponenten in Transformer-Modellen, insbesondere während der Trainingsphase. Layer Normalization stabilisiert das Training und hilft dem Modell, schneller zu konvergieren. Dropout verhindert Überanpassung, indem es zufällig Neuronen deaktiviert. Residual Connections ermöglichen es, dass die Gradienten direkt durch das Netzwerk fließen, und helfen, das Problem des verschwindenden Gradienten zu verhindern.</p> <div class="article-subsection svelte-s9hg3b" id="article-ln"><h3 class="svelte-s9hg3b">Layer Normalization</h3> <p class="svelte-s9hg3b">Layer Normalization hilft, den Trainingsprozess zu stabilisieren und die Konvergenz zu verbessern. Es funktioniert, indem die Eingaben über die Merkmale hinweg normalisiert werden, um sicherzustellen, dass der Mittelwert und die Varianz der Aktivierungen konsistent sind. Diese Normalisierung hilft, Probleme im Zusammenhang mit internen Kovariate Shift zu mildern, was es dem Modell ermöglicht, effektiver zu lernen und die Empfindlichkeit gegenüber den Anfangsgewichten zu verringern. Layer Normalization wird in jedem Transformer-Block zweimal angewendet: einmal vor dem Self-Attention-Mechanismus und einmal vor der MLP-Schicht.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-dropout"><h3 class="svelte-s9hg3b">Dropout</h3> <p class="svelte-s9hg3b">Dropout ist eine Regularisierungstechnik, die verwendet wird, um eine Überanpassung in neuronalen Netzwerken zu verhindern, indem während des Trainings ein Teil der Modellgewichte zufällig auf null gesetzt wird. Dies ermutigt das Modell, robustere Merkmale zu lernen, und reduziert die Abhängigkeit von bestimmten Neuronen, wodurch das Netzwerk besser auf neue, unbekannte Daten generalisieren kann. Während der Modellausführung wird Dropout deaktiviert. Dies bedeutet im Wesentlichen, dass wir ein Ensemble der trainierten Teilnetzwerke verwenden, was zu einer besseren Modellleistung führt.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-residual"><h3 class="svelte-s9hg3b">Residual Connections</h3> <p class="svelte-s9hg3b">Residual Connections wurden erstmals im ResNet-Modell im Jahr 2015 eingeführt. Diese architektonische Innovation revolutionierte das Deep Learning, indem sie das Training sehr tiefer neuronaler Netzwerke ermöglichte. Im Wesentlichen sind Residual Connections Abkürzungen, die eine oder mehrere Schichten umgehen und den Eingang einer Schicht zu ihrer Ausgabe hinzufügen. Dies hilft, das Problem des verschwindenden Gradienten zu mildern, was es einfacher macht, tiefe Netzwerke mit mehreren Transformer-Blöcken zu trainieren, die aufeinander gestapelt sind. Im GPT-2 werden Residual Connections zweimal in jedem Transformer-Block verwendet: einmal vor dem MLP und einmal danach, um sicherzustellen, dass die Gradienten leichter fließen und frühere Schichten während der Backpropagation ausreichende Aktualisierungen erhalten.</p></div></div> <div class="article-section svelte-s9hg3b"><h1 class="svelte-s9hg3b">Interaktive Funktionen</h1> <p class="svelte-s9hg3b">Der Transformer Erklärer wurde entwickelt, um interaktiv zu sein und Ihnen zu ermöglichen, die inneren Abläufe des Transformers zu erkunden. Hier sind einige der interaktiven Funktionen, mit denen Sie spielen können:</p> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><strong>Geben Sie Ihre eigene Textsequenz ein</strong>, um zu sehen, wie das Modell diese verarbeitet und das nächste Wort vorhersagt. Erkunden Sie die Aufmerksamkeitsgewichte, die Zwischenergebnisse und sehen Sie, wie die endgültigen Ausgabe-Wahrscheinlichkeiten berechnet werden.</li> <li class="svelte-s9hg3b"><strong>Verwenden Sie den Temperaturregler</strong>, um die Zufälligkeit der Vorhersagen des Modells zu steuern. Erkunden Sie, wie Sie das Modell deterministischer oder kreativer machen können, indem Sie den Temperaturwert ändern.</li> <li class="svelte-s9hg3b"><strong>Interagieren Sie mit den Aufmerksamkeitskarten</strong>, um zu sehen, wie das Modell sich auf verschiedene Tokens in der Eingabesequenz konzentriert. Bewegen Sie die Maus über Tokens, um deren Aufmerksamkeitsgewichte hervorzuheben und zu erkunden, wie das Modell den Kontext und die Beziehungen zwischen Wörtern erfasst.</li></ul></div> <div class="article-section svelte-s9hg3b"><h2 class="svelte-s9hg3b">Videoanleitung</h2> <div class="video-container svelte-s9hg3b"><iframe src="https://www.youtube.com/embed/ECR4oAwocjs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen class="svelte-s9hg3b"></iframe></div></div> <div class="article-section svelte-s9hg3b"><h2 class="svelte-s9hg3b">Wie ist der Transformer Erklärer implementiert?</h2> <p class="svelte-s9hg3b">Der Transformer Erklärer verfügt über ein Live-GPT-2 (klein) Modell, das direkt im Browser läuft. Dieses Modell stammt aus der PyTorch-Implementierung von GPT durch Andrej Karpathys <a href="https://github.com/karpathy/nanoGPT" title="Github" target="_blank" class="svelte-s9hg3b">nanoGPT-Projekt</a> und wurde in <a href="https://onnxruntime.ai/" title="ONNX" target="_blank" class="svelte-s9hg3b">ONNX Runtime</a> umgewandelt, um eine nahtlose Ausführung im Browser zu ermöglichen. Die Benutzeroberfläche ist in JavaScript entwickelt, mit <a href="https://kit.svelte.dev/" title="Svelte" target="_blank" class="svelte-s9hg3b">Svelte</a> als Front-End-Framework und <a href="http://D3.js" title="D3" target="_blank" class="svelte-s9hg3b">D3.js</a> zur Erstellung dynamischer Visualisierungen. Die numerischen Werte werden live entsprechend der Benutzereingabe aktualisiert.</p></div> <div class="article-section svelte-s9hg3b"><h2 class="svelte-s9hg3b">Wer hat den Transformer Erklärer entwickelt?</h2> <p class="svelte-s9hg3b">Der Transformer Erklärer wurde entwickelt von

<a href="https://aereeeee.github.io/" target="_blank" class="svelte-s9hg3b">Aeree Cho</a>,
<a href="https://www.linkedin.com/in/chaeyeonggracekim/" target="_blank" class="svelte-s9hg3b">Grace C. Kim</a>,
<a href="https://alexkarpekov.com/" target="_blank" class="svelte-s9hg3b">Alexander Karpekov</a>,
<a href="https://alechelbling.com/" target="_blank" class="svelte-s9hg3b">Alec Helbling</a>,
<a href="https://zijie.wang/" target="_blank" class="svelte-s9hg3b">Jay Wang</a>,
<a href="https://seongmin.xyz/" target="_blank" class="svelte-s9hg3b">Seongmin Lee</a>,
<a href="https://bhoov.com/" target="_blank" class="svelte-s9hg3b">Benjamin Hoover</a> und
<a href="https://poloclub.github.io/polochau/" target="_blank" class="svelte-s9hg3b">Polo Chau</a>

am Georgia Institute of Technology.</p></div></div></div></div> </div></div>  </div> 
			
			<script>
				{
					__sveltekit_1g0ftjq = {
						base: new URL(".", location).pathname.slice(0, -1),
						assets: "/transformer-explainer"
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./_app/immutable/entry/start.DbKADbpB.js"),
						import("./_app/immutable/entry/app.DPlfBxt2.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
