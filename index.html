<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="./favicon.png" />
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link href="https://fonts.googleapis.com/css2?family=Jersey+10&display=swap" rel="stylesheet" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />

		<!-- Primary Meta Tags -->
		<meta name="title" content="Transformer Explainer: LLM Transformer Model Visually Explained" />
		<meta
			name="description"
			content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT."
		/>

		<!-- Open Graph / Facebook -->
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://poloclub.github.io/transformer-explainer/" />
		<meta
			property="og:title"
			content="Transformer Explainer: LLM Transformer Model Visually Explained"
		/>
		<meta
			property="og:description"
			content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT."
		/>
		<meta
			property="og:image"
			content="https://poloclub.github.io/transformer-explainer/preview/summary.png"
		/>

		<!-- Twitter -->
		<meta property="twitter:card" content="summary_large_image" />
		<meta property="twitter:url" content="https://poloclub.github.io/transformer-explainer/" />
		<meta
			property="twitter:title"
			content="Transformer Explainer: LLM Transformer Model Visually Explained"
		/>
		<meta
			property="twitter:description"
			content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT."
		/>
		<meta
			property="twitter:image"
			content="https://poloclub.github.io/transformer-explainer/preview/summary.png"
		/>

		
		<link href="./_app/immutable/assets/0.ZHkuq1AD.css" rel="stylesheet">
		<link href="./_app/immutable/assets/HelpPopover.C2kW60Kz.css" rel="stylesheet">
		<link href="./_app/immutable/assets/2.BB2dfHRT.css" rel="stylesheet">
		<link href="./_app/immutable/assets/QKVWeightPopover.BAjhBQfT.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.DbKADbpB.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/entry.DA2jIMt1.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.if_DmnYd.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.D9ecZZ3B.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/paths.XGB25dDP.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.DPlfBxt2.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.J3wHlIuA.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.J4Kxt1gr.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.CLdE35_6.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/HelpPopover.BWfg9bBo.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.CLHtpUPn.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/QKVWeightPopover.CTvhStdE.js">
<!-- 		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-HHT51PP7TD"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag() {
				dataLayer.push(arguments);
			}
			gtag('js', new Date());

			gtag('config', 'G-HHT51PP7TD');
		</script> -->
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">  <div id="app" style="--min-screen-width:1300px;--min-column-width:22px;--predicted-color:#7E3AF2;" class="svelte-1efe9k3"><div id="landing" class="svelte-1efe9k3"><header class="svelte-1efe9k3"><div class="top-bar flex w-full items-center gap-4 px-10 py-2 pb-3 svelte-1i2onu1"><div class="logo text-bold text-gray-700 svelte-1i2onu1" data-svelte-h="svelte-793i68">T<span class="small svelte-1i2onu1">RANSFORMER</span> E<span class="small svelte-1i2onu1">XPLAINER</span></div> <div class="inputs flex grow items-center"><div class="input-wrapper w-full svelte-1i2onu1"><div class="input-area svelte-1v1a3hy">    <form class="input-form svelte-1v1a3hy"><div class="inline-flex rounded-lg shadow-sm input-btn-group" role="group"><button type="button"  class="select-button inline-flex shrink-0 items-center justify-center border border-s-0 border-gray-200 bg-white px-3 py-2 text-center text-xs font-medium text-gray-900 first:rounded-s-lg first:border-s last:rounded-e-lg svelte-1v1a3hy">Examples<svg xmlns="http://www.w3.org/2000/svg" fill="none" color="currentColor" class="shrink-0 pointer-events-none h-4 w-4 text-gray-500" role="img" aria-label="chevron down outline" viewBox="0 0 24 24"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m8 10 4 4 4-4"></path></svg> </button> <div></div>    <div class="input-container svelte-1v1a3hy disabled"><div class="editable w-full svelte-1v1a3hy"><div contenteditable="false" class="text-box svelte-1v1a3hy" placeholder="Test your own input text" role="input">Data visualization empowers users to</div> <div class="predicted svelte-1v1a3hy" role="none"><span class="svelte-1v1a3hy"> create</span></div></div>  </div></div>  <button disabled class="generate-button rounded-lg text-center text-sm shadow-sm disabled svelte-1v1a3hy" type="submit">Generate</button></form> <div class="temperature-slider shrink-0 text-gray-900 svelte-snflhu"><div class="slider-container flex w-full flex-col items-end svelte-snflhu"><div class="flex w-full shrink-0 items-center justify-between"><div class="temperature-text flex items-center gap-[2px] svelte-snflhu"><div data-svelte-h="svelte-knfc80">Temperature</div> <div id="temperature-help" class="help"><svg class="h-4 w-4 text-gray-300" xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960" fill="currentColor"><path d="M478-240q21 0 35.5-14.5T528-290q0-21-14.5-35.5T478-340q-21 0-35.5 14.5T428-290q0 21 14.5 35.5T478-240Zm-36-154h74q0-33 7.5-52t42.5-52q26-26 41-49.5t15-56.5q0-56-41-86t-97-30q-57 0-92.5 30T342-618l66 26q5-18 22.5-39t53.5-21q32 0 48 17.5t16 38.5q0 20-12 37.5T506-526q-44 39-54 59t-10 73Zm38 314q-83 0-156-31.5T197-197q-54-54-85.5-127T80-480q0-83 31.5-156T197-763q54-54 127-85.5T480-880q83 0 156 31.5T763-763q54 54 85.5 127T880-480q0 83-31.5 156T763-197q-54 54-127 85.5T480-80Z"></path></svg></div> <div></div>   </div> <div class="temperature-value svelte-snflhu"><p>1</p></div></div> <input disabled class="slider svelte-snflhu" type="range" min="0" max="17" step="1" value="8"></div> </div> </div></div></div> <div class="icons flex items-center gap-3 svelte-1i2onu1" data-svelte-h="svelte-xbnsiy"> <a href="https://arxiv.org/abs/2408.04619" target="_blank"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1i2onu1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M9 2.221V7H4.221a2 2 0 0 1 .365-.5L8.5 2.586A2 2 0 0 1 9 2.22ZM11 2v5a2 2 0 0 1-2 2H4a2 2 0 0 0-2 2v7a2 2 0 0 0 2 2 2 2 0 0 0 2 2h12a2 2 0 0 0 2-2 2 2 0 0 0 2-2v-7a2 2 0 0 0-2-2V4a2 2 0 0 0-2-2h-7Zm-6 9a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h.5a2.5 2.5 0 0 0 0-5H5Zm1.5 3H6v-1h.5a.5.5 0 0 1 0 1Zm4.5-3a1 1 0 0 0-1 1v5a1 1 0 0 0 1 1h1.376A2.626 2.626 0 0 0 15 15.375v-1.75A2.626 2.626 0 0 0 12.375 11H11Zm1 5v-3h.375a.626.626 0 0 1 .625.626v1.748a.625.625 0 0 1-.626.626H12Zm5-5a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h1a1 1 0 1 0 0-2h-1v-1h1a1 1 0 1 0 0-2h-2Z" clip-rule="evenodd"></path></svg></a>  <a href="https://www.youtube.com/watch?v=ECR4oAwocjs" target="_blank"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1i2onu1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M21.7 8.037a4.26 4.26 0 0 0-.789-1.964 2.84 2.84 0 0 0-1.984-.839c-2.767-.2-6.926-.2-6.926-.2s-4.157 0-6.928.2a2.836 2.836 0 0 0-1.983.839 4.225 4.225 0 0 0-.79 1.965 30.146 30.146 0 0 0-.2 3.206v1.5a30.12 30.12 0 0 0 .2 3.206c.094.712.364 1.39.784 1.972.604.536 1.38.837 2.187.848 1.583.151 6.731.2 6.731.2s4.161 0 6.928-.2a2.844 2.844 0 0 0 1.985-.84 4.27 4.27 0 0 0 .787-1.965 30.12 30.12 0 0 0 .2-3.206v-1.516a30.672 30.672 0 0 0-.202-3.206Zm-11.692 6.554v-5.62l5.4 2.819-5.4 2.801Z" clip-rule="evenodd"></path></svg></a>  <a href="https://github.com/poloclub/transformer-explainer" target="_blank"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1i2onu1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M12.006 2a9.847 9.847 0 0 0-6.484 2.44 10.32 10.32 0 0 0-3.393 6.17 10.48 10.48 0 0 0 1.317 6.955 10.045 10.045 0 0 0 5.4 4.418c.504.095.683-.223.683-.494 0-.245-.01-1.052-.014-1.908-2.78.62-3.366-1.21-3.366-1.21a2.711 2.711 0 0 0-1.11-1.5c-.907-.637.07-.621.07-.621.317.044.62.163.885.346.266.183.487.426.647.71.135.253.318.476.538.655a2.079 2.079 0 0 0 2.37.196c.045-.52.27-1.006.635-1.37-2.219-.259-4.554-1.138-4.554-5.07a4.022 4.022 0 0 1 1.031-2.75 3.77 3.77 0 0 1 .096-2.713s.839-.275 2.749 1.05a9.26 9.26 0 0 1 5.004 0c1.906-1.325 2.74-1.05 2.74-1.05.37.858.406 1.828.101 2.713a4.017 4.017 0 0 1 1.029 2.75c0 3.939-2.339 4.805-4.564 5.058a2.471 2.471 0 0 1 .679 1.897c0 1.372-.012 2.477-.012 2.814 0 .272.18.592.687.492a10.05 10.05 0 0 0 5.388-4.421 10.473 10.473 0 0 0 1.313-6.948 10.32 10.32 0 0 0-3.39-6.165A9.847 9.847 0 0 0 12.007 2Z" clip-rule="evenodd"></path></svg></a></div> </div></header> <main id="main" style="padding-top:0px" class="svelte-1efe9k3"><div class="flex h-full w-full items-center justify-center"><svg role="status" class="inline -mt-px animate-spin dark:text-gray-600 w-8 h-8 text-gray-300 fill-purple-600" viewBox="0 0 100 101" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M100 50.5908C100 78.2051 77.6142 100.591 50 100.591C22.3858 100.591 0 78.2051 0 50.5908C0 22.9766 22.3858 0.59082 50 0.59082C77.6142 0.59082 100 22.9766 100 50.5908ZM9.08144 50.5908C9.08144 73.1895 27.4013 91.5094 50 91.5094C72.5987 91.5094 90.9186 73.1895 90.9186 50.5908C90.9186 27.9921 72.5987 9.67226 50 9.67226C27.4013 9.67226 9.08144 27.9921 9.08144 50.5908Z" fill="currentColor"></path><path d="M93.9676 39.0409C96.393 38.4038 97.8624 35.9116 97.0079 33.5539C95.2932 28.8227 92.871 24.3692 89.8167 20.348C85.8452 15.1192 80.8826 10.7238 75.2124 7.41289C69.5422 4.10194 63.2754 1.94025 56.7698 1.05124C51.7666 0.367541 46.6976 0.446843 41.7345 1.27873C39.2613 1.69328 37.813 4.19778 38.4501 6.62326C39.0873 9.04874 41.5694 10.4717 44.0505 10.1071C47.8511 9.54855 51.7191 9.52689 55.5402 10.0491C60.8642 10.7766 65.9928 12.5457 70.6331 15.2552C75.2735 17.9648 79.3347 21.5619 82.5849 25.841C84.9175 28.9121 86.7997 32.2913 88.1811 35.8758C89.083 38.2158 91.5421 39.6781 93.9676 39.0409Z" fill="currentFill"></path></svg> </div></main></div> <div class="article h-auto w-full"><div id="description" class="svelte-s9hg3b" data-svelte-h="svelte-1ddksfh"><div class="article-section svelte-s9hg3b"><h1 class="svelte-s9hg3b">Was ist ein Transformer?</h1> <p class="svelte-s9hg3b">Der Transformer ist eine neuronale Netzwerkarchitektur, die den Ansatz der Künstlichen Intelligenz grundlegend verändert hat. Der Transformer wurde erstmals in dem wegweisenden Paper <a href="https://dl.acm.org/doi/10.5555/3295222.3295349" title="ACM Digital Library" target="_blank" class="svelte-s9hg3b">„Attention is All You Need“</a> im Jahr 2017 vorgestellt und hat sich seitdem zur Standardarchitektur für Deep-Learning-Modelle entwickelt. Diese Architektur treibt textgenerierende Modelle wie OpenAI's <strong>GPT</strong>, Meta's <strong>Llama</strong> und Google's <strong>Gemini</strong> an. Aber der Transformer wird nicht nur im Textbereich eingesetzt, sondern auch in der <a href="https://huggingface.co/learn/audio-course/en/chapter3/introduction" title="Hugging Face" target="_blank" class="svelte-s9hg3b">Audiogenerierung</a>, der <a href="https://huggingface.co/learn/computer-vision-course/unit3/vision-transformers/vision-transformers-for-image-classification" title="Hugging Face" target="_blank" class="svelte-s9hg3b">Bilderkennung</a>, der <a href="https://elifesciences.org/articles/82819" title="eLife" class="svelte-s9hg3b">Vorhersage von Proteinstrukturen</a> und sogar beim <a href="https://www.deeplearning.ai/the-batch/reinforcement-learning-plus-transformers-equals-efficiency/" title="Deep Learning AI" target="_blank" class="svelte-s9hg3b">Spielen von Spielen</a> verwendet. Dies zeigt die Vielseitigkeit des Transformers in zahlreichen Anwendungsbereichen.</p> <p class="svelte-s9hg3b">Im Wesentlichen funktionieren textgenerierende Transformer-Modelle nach dem Prinzip der <strong>Vorhersage des nächsten Wortes</strong>: Basierend auf einer Texteingabe des Benutzers, welches ist das <em>wahrscheinlichste nächste Wort</em>, das auf diese Eingabe folgt? Die Kerninnovation und Stärke der Transformer liegt in ihrem Einsatz des Self-Attention-Mechanismus, der es ihnen ermöglicht, ganze Sequenzen zu verarbeiten und langfristige Abhängigkeiten effektiver zu erfassen als frühere Architekturen.</p> <p class="svelte-s9hg3b">Die GPT-2-Familie von Modellen ist ein prominentes Beispiel für textgenerierende Transformer. Transformer Explainer wird durch das <a href="https://huggingface.co/openai-community/gpt2" title="Hugging Face" target="_blank" class="svelte-s9hg3b">GPT-2</a> (kleines) Modell angetrieben, das 124 Millionen Parameter besitzt. Obwohl es nicht das neueste oder leistungsstärkste Transformer-Modell ist, teilt es viele der gleichen architektonischen Komponenten und Prinzipien, die in den aktuellen Modellen der Spitzenklasse zu finden sind, was es zu einem idealen Ausgangspunkt für das Verständnis der Grundlagen macht.</p>
		</div> <div class="article-section svelte-s9hg3b"><h1 class="svelte-s9hg3b">Transformer-Architektur</h1> <p class="svelte-s9hg3b">Jeder textgenerierende Transformer besteht aus diesen <strong>drei zentralen Komponenten</strong>:</p> <ol class="svelte-s9hg3b"> <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Embedding</strong>: Der Texteingang wird in kleinere Einheiten, sogenannte Tokens, unterteilt, die Wörter oder Teilwörter sein können. Diese Tokens werden in numerische Vektoren umgewandelt, die als Embeddings bezeichnet werden und die semantische Bedeutung von Wörtern erfassen.</li> <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Transformer Block</strong> ist das grundlegende Bauelement des Modells, das die Eingabedaten verarbeitet und transformiert. Jeder Block umfasst: <ul class="svelte-s9hg3b"> <li class="svelte-s9hg3b"><strong>Aufmerksamkeitsmechanismus (Attention Mechanism)</strong>, die zentrale Komponente des Transformer Blocks. Er ermöglicht es den Tokens, miteinander zu kommunizieren und erfasst kontextuelle Informationen und Beziehungen zwischen Wörtern.</li> <li class="svelte-s9hg3b"><strong>MLP (Multilayer Perceptron) Layer</strong>, ein Feedforward-Netzwerk, das unabhängig auf jedes Token wirkt. Während das Ziel der Aufmerksamkeits-Schicht darin besteht, Informationen zwischen Tokens zu vermitteln, zielt das MLP darauf ab, die Repräsentation jedes Tokens zu verfeinern.</li> </ul> </li> <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Ausgabe-Wahrscheinlichkeiten (Output Probabilities)</strong>: Die finalen linearen und Softmax-Schichten transformieren die verarbeiteten Embeddings in Wahrscheinlichkeiten, wodurch das Modell Vorhersagen über das nächste Token in einer Sequenz treffen kann.</li> </ol> <div class="architecture-section svelte-s9hg3b" id="embedding"> <h2 class="svelte-s9hg3b">Embedding</h2> <p class="svelte-s9hg3b">Angenommen, du möchtest mit einem Transformer-Modell Text generieren. Du gibst ein Prompt wie dieses ein: <code class="svelte-s9hg3b">„Datenvisualisierung befähigt Benutzer zu“</code>. Dieser Eingang muss in ein Format umgewandelt werden, das das Modell verstehen und verarbeiten kann. Hier kommt das Embedding ins Spiel: Es transformiert den Text in eine numerische Darstellung, mit der das Modell arbeiten kann. Um ein Prompt in ein Embedding zu konvertieren, müssen wir 1) den Eingang tokenisieren, 2) Token-Embeddings erhalten, 3) Positionsinformationen hinzufügen und schließlich 4) Token- und Positions-Codierungen zusammenführen, um das endgültige Embedding zu erhalten. Schauen wir uns an, wie jeder dieser Schritte durchgeführt wird.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/embedding.png" width="60%" height="60%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">1</span>. Darstellung der Erweiterung der Embedding-Schicht, die zeigt, wie das Eingabe-Prompt in eine Vektordarstellung umgewandelt wird. Der Prozess umfasst <span class="fig-numbering">(1)</span> Tokenisierung, (2) Token-Embedding, (3) Positionskodierung und (4) das finale Embedding.</div> <div class="article-subsection svelte-s9hg3b"><h3 class="svelte-s9hg3b">Schritt 1: Tokenisierung</h3> <p class="svelte-s9hg3b">Die Tokenisierung ist der Prozess, bei dem der Eingabetext in kleinere, besser handhabbare Einheiten, sogenannte Tokens, zerlegt wird. Diese Tokens können ein Wort oder ein Teilwort sein. Die Wörter <code class="svelte-s9hg3b">„Data“</code> und <code class="svelte-s9hg3b">„visualization“</code> entsprechen eindeutigen Tokens, während das Wort <code class="svelte-s9hg3b">„empowers“</code> in zwei Tokens aufgeteilt wird. Der gesamte Token-Wortschatz wird vor dem Training des Modells festgelegt: Der Wortschatz von GPT-2 umfasst <code class="svelte-s9hg3b">50.257</code> eindeutige Tokens. Nachdem wir unseren Eingabetext in Tokens mit eindeutigen IDs zerlegt haben, können wir deren Vektordarstellung aus den Embeddings erhalten.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-token-embedding"><h3 class="svelte-s9hg3b">Schritt 2: Token-Embedding</h3> <p class="svelte-s9hg3b">GPT-2 Small repräsentiert jedes Token im Wortschatz als einen 768-dimensionalen Vektor; die Dimension des Vektors hängt vom Modell ab. Diese Embedding-Vektoren werden in einer Matrix mit der Form <code class="svelte-s9hg3b">(50.257, 768)</code> gespeichert, die etwa 39 Millionen Parameter enthält! Diese umfangreiche Matrix ermöglicht es dem Modell, jedem Token eine semantische Bedeutung zuzuweisen.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-positional-embedding"><h3 class="svelte-s9hg3b">Schritt 3: Positionskodierung</h3> <p class="svelte-s9hg3b">Die Embedding-Schicht kodiert auch Informationen über die Position jedes Tokens im Eingabe-Prompt. Verschiedene Modelle verwenden unterschiedliche Methoden zur Positionskodierung. GPT-2 trainiert seine eigene Positionskodierungsmatrix von Grund auf und integriert sie direkt in den Trainingsprozess.</p></div> <div class="article-subsection svelte-s9hg3b"><h3 class="svelte-s9hg3b">Schritt 4: Finales Embedding</h3> <p class="svelte-s9hg3b">Schließlich addieren wir die Token- und Positionskodierungen, um die finale Embedding-Darstellung zu erhalten. Diese kombinierte Darstellung erfasst sowohl die semantische Bedeutung der Tokens als auch deren Position in der Eingabesequenz.</p></div></div> <div class="architecture-section svelte-s9hg3b"><h2 class="svelte-s9hg3b">Transformer-Block</h2> <p class="svelte-s9hg3b">Das Herzstück der Verarbeitung im Transformer liegt im Transformer-Block, der aus Multi-Head-Self-Attention und einer Multi-Layer-Perceptron-Schicht besteht. Die meisten Modelle bestehen aus mehreren solcher Blöcke, die nacheinander gestapelt sind. Die Repräsentationen der Tokens entwickeln sich durch die Schichten, vom ersten Block bis zum zwölften, wodurch das Modell ein komplexes Verständnis für jedes Token aufbaut. Dieser schichtweise Ansatz führt zu höherwertigen Repräsentationen der Eingabe.</p> <div class="article-subsection svelte-s9hg3b" id="self-attention"> <h3 class="svelte-s9hg3b">Multi-Head-Self-Attention</h3> <p class="svelte-s9hg3b">Der Self-Attention-Mechanismus ermöglicht es dem Modell, sich auf relevante Teile der Eingabesequenz zu konzentrieren, wodurch es komplexe Beziehungen und Abhängigkeiten innerhalb der Daten erfassen kann. Schauen wir uns an, wie diese Self-Attention Schritt für Schritt berechnet wird.</p> <div class="article-subsection-l2 svelte-s9hg3b"> <h4 class="svelte-s9hg3b">Schritt 1: Query-, Key- und Value-Matrizen</h4> <div class="figure svelte-s9hg3b"><img src="./article_assets/QKV.png" width="80%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">2</span>. Berechnung der Query-, Key- und Value-Matrizen aus dem ursprünglichen Embedding.</div> <p class="svelte-s9hg3b">Der Embedding-Vektor jedes Tokens wird in drei Vektoren transformiert: <span class="q-color svelte-s9hg3b">Query (Q)</span>, <span class="k-color svelte-s9hg3b">Key (K)</span> und <span class="v-color svelte-s9hg3b">Value (V)</span>. Diese Vektoren werden abgeleitet, indem die Eingabe-Embedding-Matrix mit gelernten Gewichtsmatrizen für <span class="q-color svelte-s9hg3b">Q</span>, <span class="k-color svelte-s9hg3b">K</span> und <span class="v-color svelte-s9hg3b">V</span> multipliziert wird.</p> <p class="svelte-s9hg3b">Hier ist eine Analogie zur Websuche, die uns hilft, ein besseres Verständnis für diese Matrizen zu entwickeln:</p> <ul class="svelte-s9hg3b"> <li class="svelte-s9hg3b"><strong class="q-color font-medium svelte-s9hg3b">Query (Q)</strong> ist der Suchtext, den du in die Suchleiste einer Suchmaschine eingibst. Dies ist das Token, über das du <em>„mehr Informationen erhalten möchtest“</em>.</li> <li class="svelte-s9hg3b"><strong class="k-color font-medium svelte-s9hg3b">Key (K)</strong> ist der Titel jeder Webseite im Suchergebnisfenster. Er repräsentiert die möglichen Tokens, auf die die Abfrage zugreifen kann.</li> <li class="svelte-s9hg3b"><strong class="v-color font-medium svelte-s9hg3b">Value (V)</strong> ist der eigentliche Inhalt der angezeigten Webseiten. Nachdem wir den passenden Suchbegriff (Query) mit den relevanten Ergebnissen (Key) abgeglichen haben, möchten wir den Inhalt (Value) der relevantesten Seiten abrufen.</li> </ul> <p class="svelte-s9hg3b">Durch die Verwendung dieser QKV-Werte kann das Modell Aufmerksamkeitswerte berechnen, die bestimmen, wie viel Fokus jedes Token bei der Generierung von Vorhersagen erhalten sollte.</p></div> <div class="article-subsection-l2 svelte-s9hg3b"> <h4 class="svelte-s9hg3b">Schritt 2: Maskierte Self-Attention</h4> <p class="svelte-s9hg3b">Die maskierte Self-Attention ermöglicht es dem Modell, Sequenzen zu generieren, indem es sich auf relevante Teile der Eingabe konzentriert, während der Zugriff auf zukünftige Tokens verhindert wird.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/attention.png" width="80%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">3</span>. Verwendung von Query-, Key- und Value-Matrizen zur Berechnung der maskierten Self-Attention.</div> <ul class="svelte-s9hg3b"> <li class="svelte-s9hg3b"><strong>Aufmerksamkeitswert (Attention Score)</strong>: Das Skalarprodukt der <span class="q-color svelte-s9hg3b">Query</span> und <span class="k-color svelte-s9hg3b">Key</span> Matrizen bestimmt die Ausrichtung jeder Query auf jeden Key und erzeugt eine quadratische Matrix, die die Beziehung zwischen allen Eingabetokens widerspiegelt.</li> <li class="svelte-s9hg3b"><strong>Maskierung</strong>: Eine Maske wird auf das obere Dreieck der Aufmerksamkeitsmatrix angewendet, um zu verhindern, dass das Modell auf zukünftige Tokens zugreift, indem diese Werte auf negative Unendlichkeit gesetzt werden. Das Modell muss lernen, das nächste Token vorherzusagen, ohne in die Zukunft zu „blicken“.</li> <li class="svelte-s9hg3b"><strong>Softmax</strong>: Nach der Maskierung wird der Aufmerksamkeitswert durch die Softmax-Operation in eine Wahrscheinlichkeit umgewandelt, bei der der Exponent jedes Aufmerksamkeitswerts berechnet wird. Jede Zeile der Matrix summiert sich zu eins und gibt die Relevanz jedes anderen Tokens links davon an.</li> </ul> </div> <div class="article-subsection-l2 svelte-s9hg3b"> <h4 class="svelte-s9hg3b">Schritt 3: Ausgabe</h4> <p class="svelte-s9hg3b">Das Modell verwendet die maskierten Self-Attention-Werte und multipliziert sie mit der <span class="v-color svelte-s9hg3b">Value</span> Matrix, um die <span class="purple-color svelte-s9hg3b">endgültige Ausgabe</span> des Self-Attention-Mechanismus zu erhalten. GPT-2 hat <code class="svelte-s9hg3b">12</code> Self-Attention-Köpfe, die jeweils unterschiedliche Beziehungen zwischen Tokens erfassen. Die Ausgaben dieser Köpfe werden zusammengeführt und durch eine lineare Projektion weiterverarbeitet.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-activation"><h3 class="svelte-s9hg3b">MLP: Multi-Layer Perceptron</h3> <div class="figure svelte-s9hg3b"><img src="./article_assets/mlp.png" width="70%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">4</span>. Verwendung der MLP-Schicht zur Projektion der Self-Attention-Repräsentationen in höhere Dimensionen, um die Repräsentationsfähigkeit des Modells zu verbessern.</div> <p class="svelte-s9hg3b">Nachdem die verschiedenen Köpfe der Self-Attention die vielfältigen Beziehungen zwischen den Eingabetokens erfasst haben, werden die zusammengeführten Ausgaben durch die Multilayer-Perceptron (MLP)-Schicht geleitet, um die Repräsentationsfähigkeit des Modells zu erhöhen. Der MLP-Block besteht aus zwei linearen Transformationen mit einer GELU-Aktivierungsfunktion dazwischen. Die erste lineare Transformation erhöht die Dimensionalität der Eingabe um das Vierfache von <code class="svelte-s9hg3b">768</code> auf <code class="svelte-s9hg3b">3072</code>. Die zweite lineare Transformation reduziert die Dimensionalität wieder auf die ursprüngliche Größe von <code class="svelte-s9hg3b">768</code>, um sicherzustellen, dass die nachfolgenden Schichten Eingaben mit konsistenter Dimensionalität erhalten. Im Gegensatz zum Self-Attention-Mechanismus verarbeitet das MLP Tokens unabhängig voneinander und mappt sie einfach von einer Repräsentation zur nächsten.</p></div> <div class="architecture-section svelte-s9hg3b" id="article-prob"> <h2 class="svelte-s9hg3b">Ausgabewahrscheinlichkeiten</h2> <p class="svelte-s9hg3b">Nachdem die Eingabe durch alle Transformer-Blöcke verarbeitet wurde, wird die Ausgabe durch die finale lineare Schicht geleitet, um sie für die Token-Vorhersage vorzubereiten. Diese Schicht projiziert die finalen Repräsentationen in einen <code class="svelte-s9hg3b">50.257</code>-dimensionalen Raum, in dem jedes Token im Wortschatz einen entsprechenden Wert hat, der <code class="svelte-s9hg3b">logit</code> genannt wird. Jedes Token könnte das nächste Wort sein, daher ermöglicht uns dieser Prozess, diese Tokens einfach nach ihrer Wahrscheinlichkeit zu sortieren, das nächste Wort zu sein. Anschließend wenden wir die Softmax-Funktion an, um die Logits in eine Wahrscheinlichkeitsverteilung umzuwandeln, die sich auf eins summiert. Dies ermöglicht es uns, das nächste Token basierend auf seiner Wahrscheinlichkeit zu wählen.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/softmax.png" width="60%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Abbildung <span class="attention">5</span>. Jedem Token im Wortschatz wird eine Wahrscheinlichkeit basierend auf den Logits des Modells zugewiesen. Diese Wahrscheinlichkeiten bestimmen die Wahrscheinlichkeit, dass jedes Token das nächste Wort in der Sequenz ist.</div> <p id="article-temperature" class="svelte-s9hg3b">Der letzte Schritt besteht darin, das nächste Token zu generieren, indem aus dieser Verteilung gewählt wird. Der Hyperparameter <code class="svelte-s9hg3b">temperature</code> spielt in diesem Prozess eine entscheidende Rolle. Mathematisch gesehen ist es eine sehr einfache Operation: Die Logits des Modells werden einfach durch die <code class="svelte-s9hg3b">temperature</code> dividiert:</p></p> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><p class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature = 1</code>: Das Dividieren der Logits durch eins hat keinen Einfluss auf die Softmax-Ausgaben.</li> <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature &lt; 1</code>: Eine niedrigere Temperatur macht das Modell selbstbewusster und deterministischer, indem die Wahrscheinlichkeitsverteilung geschärft wird, was zu vorhersehbareren Ausgaben führt.</li> <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature &gt; 1</code>: Eine höhere Temperatur erzeugt eine weichere Wahrscheinlichkeitsverteilung, die mehr Zufälligkeit im generierten Text zulässt – was manche als Modell-<em>„Kreativität“</em> bezeichnen.</li></ul> <p class="svelte-s9hg3b">Passe die Temperatur an und sieh, wie du das Gleichgewicht zwischen deterministischen und vielfältigen Ausgaben finden kannst!</p></div> <div class="architecture-section svelte-s9hg3b"> <h2 class="svelte-s9hg3b">Erweiterte Architekturmerkmale</h2> <p class="svelte-s9hg3b">Es gibt mehrere erweiterte Architekturmerkmale, die die Leistung von Transformer-Modellen verbessern. Während sie für die Gesamtleistung des Modells wichtig sind, sind sie nicht so entscheidend, um die Kernkonzepte der Architektur zu verstehen. Layer-Normalisierung, Dropout und Residual Connections sind entscheidende Komponenten in Transformer-Modellen, insbesondere während der Trainingsphase. Die Layer-Normalisierung stabilisiert das Training und hilft dem Modell, schneller zu konvergieren. Dropout verhindert Overfitting, indem Neuronen zufällig deaktiviert werden. Residual Connections ermöglichen es den Gradienten, direkt durch das Netzwerk zu fließen und helfen, das Problem des verschwindenden Gradienten zu verhindern.</p> <div class="article-subsection svelte-s9hg3b" id="article-ln"> <h3 class="svelte-s9hg3b">Layer-Normalisierung</h3> <p class="svelte-s9hg3b">Die Layer-Normalisierung hilft, den Trainingsprozess zu stabilisieren und die Konvergenz zu verbessern. Sie funktioniert, indem die Eingaben über die Merkmale hinweg normalisiert werden, wodurch sichergestellt wird, dass der Mittelwert und die Varianz der Aktivierungen konsistent sind. Diese Normalisierung trägt dazu bei, Probleme im Zusammenhang mit dem internen Covariaten-Shift zu mildern, sodass das Modell effektiver lernen kann und die Empfindlichkeit gegenüber den Anfangsgewichten verringert wird. Die Layer-Normalisierung wird in jedem Transformer-Block zweimal angewendet: einmal vor dem Self-Attention-Mechanismus und einmal vor der MLP-Schicht.</p> </div> <div class="article-subsection svelte-s9hg3b" id="article-dropout">
<h3 class="svelte-s9hg3b">Dropout</h3> <p class="svelte-s9hg3b">Dropout ist eine Regularisierungstechnik, die verwendet wird, um Overfitting in neuronalen Netzwerken zu verhindern, indem während des Trainings zufällig ein Teil der Modellgewichte auf null gesetzt wird. Dies fördert das Erlernen robusterer Merkmale und verringert die Abhängigkeit von bestimmten Neuronen, was dem Netzwerk hilft, besser auf neue, unbekannte Daten zu generalisieren. Während der Modellinferenz wird Dropout deaktiviert. Das bedeutet im Wesentlichen, dass wir ein Ensemble der trainierten Teilnetzwerke verwenden, was zu einer besseren Modellleistung führt.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-residual"> <h3 class="svelte-s9hg3b">Residual Connections</h3> <p class="svelte-s9hg3b">Residual-Verbindungen wurden erstmals im ResNet-Modell im Jahr 2015 eingeführt. Diese architektonische Innovation revolutionierte das Deep Learning, indem sie das Training sehr tiefer neuronaler Netzwerke ermöglichte. Im Wesentlichen sind Residual-Verbindungen Abkürzungen, die eine oder mehrere Schichten umgehen, indem sie die Eingabe einer Schicht zu ihrem Ausgang addieren. Dies hilft, das Problem des verschwindenden Gradienten zu mildern, was es erleichtert, tiefe Netzwerke mit mehreren übereinander gestapelten Transformer-Blöcken zu trainieren. In GPT-2 werden Residual-Verbindungen innerhalb jedes Transformer-Blocks zweimal verwendet: einmal vor dem MLP und einmal danach, was sicherstellt, dass die Gradienten leichter fließen und frühere Schichten während der Rückwärtsausbreitung ausreichend Updates erhalten.</p></div></div> <div class="article-section svelte-s9hg3b"> <h1 class="svelte-s9hg3b">Interaktive Funktionen</h1> <p class="svelte-s9hg3b">Transformer Explainer wurde entwickelt, um interaktiv zu sein und es dir zu ermöglichen, die inneren Abläufe des Transformers zu erkunden. Hier sind einige der interaktiven Funktionen, mit denen du experimentieren kannst:</p> <ul class="svelte-s9hg3b"> <li class="svelte-s9hg3b"><strong>Gib deine eigene Textsequenz ein</strong>, um zu sehen, wie das Modell sie verarbeitet und das nächste Wort vorhersagt. Untersuche Aufmerksamkeitsgewichte, Zwischenberechnungen und sieh dir an, wie die endgültigen Ausgabewahrscheinlichkeiten berechnet werden.</li> <li class="svelte-s9hg3b"><strong>Verwende den Temperaturregler</strong>, um die Zufälligkeit der Modellvorhersagen zu steuern. Erkunde, wie du durch Ändern des Temperaturwerts das Modell deterministischer oder kreativer machen kannst.</li> <li class="svelte-s9hg3b"><strong>Interagiere mit Aufmerksamkeitskarten</strong>, um zu sehen, wie das Modell sich auf verschiedene Tokens in der Eingabesequenz konzentriert. Fahre mit der Maus über Tokens, um ihre Aufmerksamkeitsgewichte hervorzuheben, und untersuche, wie das Modell Kontext und Beziehungen zwischen Wörtern erfasst.</li> </ul></div> <div class="article-section svelte-s9hg3b"> <h2 class="svelte-s9hg3b">Video-Tutorial</h2> <div class="video-container svelte-s9hg3b"> <iframe src="https://www.youtube.com/embed/ECR4oAwocjs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen class="svelte-s9hg3b"></iframe> </div> </div> <div class="article-section svelte-s9hg3b"><h2 class="svelte-s9hg3b">Wie ist der Transformer Explainer implementiert?</h2> <p class="svelte-s9hg3b">Der Transformer Explainer nutzt ein live laufendes GPT-2 (small) Modell direkt im Browser. Dieses Modell stammt aus der PyTorch-Implementierung von GPT durch Andrej Karpathys <a href="https://github.com/karpathy/nanoGPT" title="Github" target="_blank" class="svelte-s9hg3b">nanoGPT-Projekt</a> und wurde in <a href="https://onnxruntime.ai/" title="ONNX" target="_blank" class="svelte-s9hg3b">ONNX Runtime</a> konvertiert, um eine nahtlose Ausführung im Browser zu ermöglichen. Die Benutzeroberfläche ist in JavaScript gebaut, mit <a href="https://kit.svelte.dev/" title="Svelte" target="_blank" class="svelte-s9hg3b">Svelte</a> als Frontend-Framework und <a href="http://D3.js" title="D3" target="_blank" class="svelte-s9hg3b">D3.js</a> zur Erstellung dynamischer Visualisierungen. Numerische Werte werden live aktualisiert, nachdem der Benutzer Eingaben gemacht hat.</p></div> <div class="article-section svelte-s9hg3b"> <h2 class="svelte-s9hg3b">Wer hat den Transformer Explainer entwickelt?</h2> <p class="svelte-s9hg3b">Der Transformer Explainer wurde von <a href="https://aereeeee.github.io/" target="_blank" class="svelte-s9hg3b">Aeree Cho</a>, <a href="https://www.linkedin.com/in/chaeyeonggracekim/" target="_blank" class="svelte-s9hg3b">Grace C. Kim</a>, <a href="https://alexkarpekov.com/" target="_blank" class="svelte-s9hg3b">Alexander Karpekov</a>, <a href="https://alechelbling.com/" target="_blank" class="svelte-s9hg3b">Alec Helbling</a>, <a href="https://zijie.wang/" target="_blank" class="svelte-s9hg3b">Jay Wang</a>, <a href="https://seongmin.xyz/" target="_blank" class="svelte-s9hg3b">Seongmin Lee</a>, <a href="https://bhoov.com/" target="_blank" class="svelte-s9hg3b">Benjamin Hoover</a> und <a href="https://poloclub.github.io/polochau/" target="_blank" class="svelte-s9hg3b">Polo Chau</a> am Georgia Institute of Technology entwickelt.</p>
<p class="svelte-s9hg3b">Übersetzt und angepasst vom <a href="https://bil-hamburg.de" target="_blank" class="svelte-s9hg3b">Business Innovation Lab</a> der Hochschule für Angewandte Wissenschaften Hamburg im Rahmen des <a href="https://digitalzentrum-hamburg.de/" target="_blank" class="svelte-s9hg3b">Mittelstand Digital-Zentrum Hamburg</a>.</p>

</div></div></div></div> </div></div>  </div> 
			
			<script>
				{
					__sveltekit_1g0ftjq = {
						base: new URL(".", location).pathname.slice(0, -1),
						assets: "/transformer-explainer"
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./_app/immutable/entry/start.DbKADbpB.js"),
						import("./_app/immutable/entry/app.DPlfBxt2.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
